{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Core consistency\n\nA popular metric for evaluating the validity of PARAFAC models is the core consistency diagnostic (sometimes called\nCORCONDIA) :cite:p:`bro2003new`. In this example, we'll see how, why and when the core consistency works well.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start by fitting a four-component model to the amino acids dataset. First, we import the relevant modules\nand create a utility function to fit many PARAFAC models.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom tensorly.decomposition import parafac\n\nimport tlviz\n\n\ndef fit_parafac(X, num_components, num_inits=5):\n    model_candidates = [\n        parafac(\n            X,\n            num_components,\n            n_iter_max=1000,\n            tol=1e-8,\n            init=\"random\",\n            orthogonalise=True,\n            linesearch=True,\n            random_state=i,\n        )\n        for i in range(num_inits)\n    ]\n    cp_tensor = tlviz.multimodel_evaluation.get_model_with_lowest_error(model_candidates, X)\n    return tlviz.postprocessing.postprocess(cp_tensor, dataset=aminoacids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we load the data and fit a PARAFAC model to it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "aminoacids = tlviz.data.load_aminoacids()\nfour_component_cp = fit_parafac(aminoacids.data, 4, num_inits=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we want to check the validity of this model. We know that with PARAFAC, we cannot have any interactions between\nthe components. Mathematically this means that our tensor entries, $x_{ijk}$ is described by\n\n\\begin{align}{ijk} = \\sum_{r=1}^R a_{ir}b_{jr}c_{kr},\\end{align}\n\nwhere $a_{ir},b_{jr}$ and $c_{kr}$ are entries in the factor matrices, $\\mathbf{A}, \\mathbf{B}$ and\n$\\mathbf{C}$, respectively (we keep the weight multiplied into the factor matrices).\n\nIf we want to allow for interactions between our components, we could use a *Tucker model*. This model introduces\nlinear interactions and represents a tensor by\n\n\\begin{align}x_{ijk} = \\sum_{r_0, r_1, r_2 = 1}^R g_{r_0 r_1 r_2} a_{ir_0}b_{jr_1}c_{kr_2},\\end{align}\n\nwhere $\\mathbf{g}_{r_0 r_1 r_2}$ is an entry in the $R \\times R \\times R$ *core array*. We see that the\nPARAFAC model is a special case of the Tucker model, where the superdiagonal entries are equal to $1$ and the\noff-diagonal entries are equal to $0$ ($\\mathbf{g}_{r_0 r_1 r_2} = 1$ if $r_0 = r_1 = r_2$ and\n$0$ otherwise). We denote this special core tensor by $\\mathcal{T}$.\n\nWe know that if our dataset follows the PARAFAC model and if we have recovered the correct components, we will not\nget a better fit by allowing for interactions between the components. To check this, we can compute and inspect the\noptimal $\\mathcal{G}$ given the factor matrices we found with PARAFAC.\n\nLet's look at the entries we get for $\\mathcal{G}$ with the PARAFAC model we fitted to the amino acids dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tlviz.visualisation.core_element_heatmap(four_component_cp, aminoacids)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This plot shows interaction between the different components. For example, we see that there are high values\nin the four corners of slab 0 and 3, which indicates a strong two-compponent interaction between component 3 and\ncomponent 1. There are also high values in the four corners of slab 1, which shows that there is a three-component\ninteraction between component 0, 1 and 3.\n\nA downside with the core element heatmap is that we can only create it for third-order tensors. Also, while the\nheatmap shows where the interactions are, it can be difficult to see exactly how strong they are. It is, therefore,\nalso helpful to look at a plot of the core elements, sorted, so the superdiagonal are plotted first, and the\noff-diagonal entries are plotted afterwards.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tlviz.visualisation.core_element_plot(four_component_cp, aminoacids)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we also see that the core tensor is not similar to $\\mathcal{T}$ (which is plotted with the straight\nline). Therefore, we can conclude that the amino acids dataset likely does not follow a 4-component PARAFAC model.\n\nTo understand why this works, we can consider a noisy dataset that follows an $R$-component PARAFAC model. If\nwe fit an $R$-component model to this data, we should find the components, and there will be no interaction\nbetween them. However, if we fit an $R+1$-component model to this data, we will get an extra component that\nmodels the noise. This additional component is forced to be trilinear with no interaction, but the process it\ndescribes (the noise) is not trilinear. Therefore, this model can better describe the noise by adding interactions\nwith the other modes.\n\nIt is common to summarise the above analysis into a single metric by computing the relative difference between $\\mathcal{G}$ and $\\mathcal{T}$. This metric is called the core consistency diagnostic (sometimes called CORCONDIA), and is defined as\n\n\\begin{align}\\text{CC} = 100 \\left(1 - \\frac{\\| \\mathcal{G} - \\mathcal{T} \\|^2}{R}\\right).\\end{align}\n\nA core consistency of 100 signifies that no linear interactions can improve the fit, while a low core consistency\nindicates that we can improve the fit by including linear interactions (sometimes, the core consistency is defined\nby dividing by $\\| \\mathcal{G} \\|^2$ instead of R). We can use the core consistency to select an appropriate\nPARAFAC model from a set of candidates. Below is an example where we have done that\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "models = {}\nfor rank in [1, 2, 3, 4, 5]:\n    models[rank] = fit_parafac(aminoacids.data, rank, num_inits=5)\n\nax = tlviz.visualisation.scree_plot(models, aminoacids, metric=\"Core consistency\")\nax.set_ylim(0, 105)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we see that for one, two and three components, the core consistency is high, but when we look at four\ncomponents, the core consistency becomes very small. The three-component model is, therefore, a good choice.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tlviz.visualisation.core_element_heatmap(models[3], aminoacids)\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tlviz.visualisation.core_element_plot(models[3], aminoacids)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we see that $\\mathcal{G}$ and $\\mathcal{T}$ are very similar, which indicates that the\nthree-component model could be a good choice for this dataset.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final note\nIt is important to note that the core consistency is not guaranteed to tell us which model to use. There are several\ncases where the core consistency may fail. Some examples are:\n\n #. If we have many components, then even minor differences on the off-diagonal can sum up and reduce the core\n    consistency measurably,\n #. if we have data that doesn't follow the assumptions of PARAFAC but where the PARAFAC components can still\n    provide valuable insight,\n #. if we need a component to model structural noise to correctly recover the meaningful components.\n #. or if the data is very noisy, the model can potentially improve the fit by allowing for interactions even if we\n    know the true underlying factor matrices.\n\nThe core consistency can be very low in all these cases, even for the \"best\" model. Therefore, it is essential to\nconsider more than just the core consistency when selecting the best model. Examples are initialisation stability,\nsplit half stability, and looking at the component vectors to see if they make sense.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}