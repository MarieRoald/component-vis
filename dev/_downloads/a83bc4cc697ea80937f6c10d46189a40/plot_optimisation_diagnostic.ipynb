{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Optimisation diagnostics with PARAFAC models\n\nFitting PARAFAC models entails solving a non-convex optimisation problem. To do this, we use alternating least squares,\n(ALS). However, ALS is not guaranteed to converge to the global minimum. It is therefore often advised to use several random\ninitialisations and pick the one that obtained the lowest loss value.\n\nNow, a logical question is, how can we be sure that the decomposition we ended up with is good? There is,\nunfortunately, no easy answer to this question. But, if we inspect the runs, we can become more confident in our\nresults.\n\nWe start by importing the relevant code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorly.decomposition import parafac\n\nimport tlviz\nfrom tlviz.factor_tools import factor_match_score\nfrom tlviz.multimodel_evaluation import (\n    get_model_with_lowest_error,\n    similarity_evaluation,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we create a simulated dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rank = 5\ncp_tensor, X = tlviz.data.simulated_random_cp_tensor((10, 15, 20), rank, noise_level=0.05, seed=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we fit ten random initialisations to this dataset, storing the CP tensors and relative SSE.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "estimated_cp_tensors = []\nerrors = []\nfor init in range(10):\n    print(init)\n    est_cp, rec_errors = parafac(X, rank, n_iter_max=100, init=\"random\", return_errors=True, random_state=init)\n    estimated_cp_tensors.append(est_cp)\n    errors.append(np.array(rec_errors) ** 2)  # rec_errors is relative norm error, we want relative SSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And get the initialisation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "first_attempt = get_model_with_lowest_error(estimated_cp_tensors, X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To see if we have a good initialisation, we use the optimisation diagnostics plots,\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tlviz.visualisation.optimisation_diagnostic_plots(errors, n_iter_max=100)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These plots show the final loss value for each initialisation,\nwith markers that signify if the different initialisations converged and the loss plot for each initialisation.\nWe want reproducible results, so ideally, many of the initialisations should achieve the same low loss value.\nWe also want the initialisations to converge.\n\nIn this case, we see that we get many different loss values, and they did not converge.\nThese observations indicate that our optimisation procedure did not converge to a good minimum.\nAnother thing we can look at is how similar the different initialisations are with the selected initialisation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(similarity_evaluation(first_attempt, estimated_cp_tensors))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the different initialisations do not resemble the selected initialisation much. So the optimisation\nseems unstable. Let's also compare the selected  model with the true decomposition\n(which is only possible because we have simulated data and therefore know the true decomposition).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(factor_match_score(first_attempt, cp_tensor))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So the decomposition is, as we expected, not very good... Let's try to increase the maximum number of iterations!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "estimated_cp_tensors = []\nerrors = []\nfinal_errors = []\nfor init in range(10):\n    print(init)\n    est_cp, rec_errors = parafac(X, rank, n_iter_max=1000, init=\"random\", return_errors=True, random_state=init)\n    estimated_cp_tensors.append(est_cp)\n    errors.append(np.array(rec_errors) ** 2)  # rec_errors is relative norm error, we want relative SSE\nsecond_attempt = get_model_with_lowest_error(estimated_cp_tensors, X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And plot the optimisation diagnostics plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tlviz.visualisation.optimisation_diagnostic_plots(errors, 1000)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At least some converged, and a couple reached the same loss value.\nThese results are better but not ideal.\nWe don't want it to be challenging to find a good initialisation!\nLet's compare the similarity between the different initialisations and the selected initialisation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(similarity_evaluation(second_attempt, estimated_cp_tensors))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ok, we got two similar decompositions.\nNot ideal, but at least there was more than one good initialisation.\nLet's try some more initialisations before we compare with the true decomposition.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for init in range(10, 20):\n    print(init)\n    est_cp, rec_errors = parafac(X, rank, n_iter_max=1000, init=\"random\", return_errors=True, random_state=init)\n    estimated_cp_tensors.append(est_cp)\n    errors.append(np.array(rec_errors) ** 2)  # rec_errors is relative norm error, we want relative SSE\nthird_attempt = tlviz.multimodel_evaluation.get_model_with_lowest_error(estimated_cp_tensors, X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And let's look at the optimisation diagnostics plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tlviz.visualisation.optimisation_diagnostic_plots(errors, 1000)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have many initialisations that converged to the same loss value!\nThat is exactly the behaviour that we want.\nLet's compare the similarity between them and the selected decomposition too.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(similarity_evaluation(third_attempt, estimated_cp_tensors))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we also see that many of the initialisations were similar.\nIf these were different, we would be in trouble.\nSince then, there would likely be many different minima with the same loss value.\nLuckily, that was not the case.\nFinally, let's compare our selected model with the true decomposition!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(factor_match_score(cp_tensor, third_attempt))\n\ndecompositions = {\n    \"True\": cp_tensor,\n    \"First attempt\": first_attempt,\n    \"Second attempt\": second_attempt,\n    \"Third attempt\": third_attempt,\n}\ntlviz.visualisation.component_comparison_plot(decompositions, row=\"component\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}