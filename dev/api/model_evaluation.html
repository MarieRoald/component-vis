
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Model evaluation &#8212; TLViz 0.0.9 documentation</title> 
<link rel="stylesheet" href="../_static/tensorly_style.css">
<link rel="apple-touch-icon" sizes="180x180" href="../_static/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../_static/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../_static/favicon/favicon-16x16.png">
<link rel="manifest" href="../_static/favicon/site.webmanifest">
<link rel="mask-icon" href="../_static/favicon/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="../_static/favicon/favicon.ico">
<meta name="theme-color" content="#ffffff">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tensorly_style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />

  
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
 <script src="../_static/navbar_burger.js"></script>
 <script defer src="https://use.fontawesome.com/releases/v5.14.0/js/all.js"></script>
 
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Multi-model evaluation" href="multimodel_evaluation.html" />
    <link rel="prev" title="Factor tools" href="factor_tools.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

  </head>
<body  class="has-navbar-fixed-top">

  <header>
    <navbar>
      <nav class="navbar top-navbar is-fixed-top has-shadow is-flex-wrap-wrap" role="navigation" aria-label="main top navigation">
        <div class="navbar-brand">
        <!-- Always displayed, last item has to be navbar-burger -->

          <a class="navbar-item" href="../index.html">
            <img src="../_static/tlviz_logo.svg" height="28">
          </a>

          <!-- <a class="navbar-item is-hidden-desktop" href="../index.html">
            <span class="icon"><i class="fa fa-home" aria-hidden="true"></i></span>
          </a> -->
          <a class="navbar-item is-hidden-desktop" href="https://github.com/tensorly/viz" target="_blank">
              <span class="icon"><i class="fab fa-github"></i></span>
          </a>

          <a role="button" class="navbar-burger" data-target="top-nav-menu" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
          </a>

        </div>
        
        <div class="navbar-menu" id="top-nav-menu">
        <!-- only on larger displays (> 1024px) -->

          <div class="navbar-start">
          <!-- RIGHT -->
            <a class="navbar-item" href="../about_tensors.html">
              Introduction
            </a>
            <a class="navbar-item" href="../installation.html">
              Installation
            </a>
            <a class="navbar-item" href="../auto_examples/index.html">
              Examples
            </a>
            <a class="navbar-item" href="../api.html">
              API
            </a>
            <a class="navbar-item" href="https://tensorly.org" target="_blank">
              TensorLy
            </a>

          </div>
        
          <div class="navbar-end">
            <div class="navbar-item">
            <!-- LEFT -->

            <!-- <a class="navbar-item is-hidden-touch" href="../index.html">
              <span class="icon-text">
                <span class="icon">
                  <i class="fa fa-home"></i>
                </span>
                <span>Home</span>
              </span>
              <span class="icon"><i class="fa fa-home" aria-hidden="true"></i></span>
            </a> -->
            <a class="button is-hidden-touch is-dark" href="https://github.com/tensorly/viz" target="_blank">
              <span class="icon-text">
                <span class="icon is-large">
                  <i class="fab fa-github"></i>
                </span>
                <span>Github</span>
              </span>
                <!-- <span class="icon"><i class="fab fa-github"></i></span> -->
            </a>

            </div> <!-- navbar item -->
          </div> <!-- navbar end -->
        </div> <!-- only large items -->

      </nav>
      
    </navbar>
  </header>

  <div id="column-container">
  <div class="columns is-mobile is-centered">
	
      <div class="column is-10-mobile is-one-third-tablet is-3-desktop is-hidden-mobile" id="sidebar">
    <!-- Side menu  -->
    <aside class="sticky-nav sidebar-menu">
<div class="sidebar-search">
  <form class="field" id="searchbox" role="search" action="../search.html" method="get">
    <!-- <label class="label" id="searchlabel">Quick search</label> -->
    <div class="field has-addons">
      <div class="control is-expanded">
        <input class="input" type="text" placeholder="Search in TLViz" name="q" aria-labelledby="searchlabel">
      </div>
      <div class="control">
        <input class="button is-info" type="submit" value="Go" />
      </div>
    </div>
  </form>
  <script>$('#searchbox').show(0);</script>
  <script>
  $(document).ready(function() {
    Document.highlightSearchWords = function() {
      var params = $.getQueryParameters();
      var terms = (params.highlight) ? params.highlight[0].split(/\s+/) : [];
      if (terms.length) {
        var body = $('div.body');
        if (!body.length) {
          body = $('body');
        }
        window.setTimeout(function() {
          $.each(terms, function() {
            body.highlightText(this.toLowerCase(), 'highlighted');
          });
        }, 10);
        $('<p class="highlight-link"><a href="javascript:Documentation.' +
          'hideSearchWords()">' + _('Hide All')
          + '<span class="tag is-delete"></span>'
          + '</a></p>')
            .appendTo($('#searchbox'));
      }
    };
  });
  </script>
</div>
      
      <div class="sidebar-menu-toc">
      <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../about_tensors.html">What are tensors and tensor decompositions?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Gallery of examples</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../api.html">API Reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="postprocessing.html">Post-processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="factor_tools.html">Factor tools</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Model evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="multimodel_evaluation.html">Multi-model evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="outliers.html">Outlier detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="visualisation.html">Visualisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="data.html">Example datasets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../tensorly_backends.html">Working with TensorLy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contribution guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">References</a></li>
</ul>
 
      </div>
    </aside>
  </div>
  

    <div class="column main-column">

      <!-- Main content  -->
      <section class="main-section">

        <!-- Toggle menu button -->
		
        <div class="side-menu-toggle">
          <button class="button" id="toggle-sidebar" onclick="toggle_sidebar()">
            <span class="icon"><i class="fa fa-bars" aria-hidden="true"></i></span>
            <span>menu</span> 
          </button>
        </div>
        

        <div class="content main-content">
          
  <section id="module-tlviz.model_evaluation">
<span id="model-evaluation"></span><h1>Model evaluation<a class="headerlink" href="#module-tlviz.model_evaluation" title="Permalink to this headline">¶</a></h1>
<p><strong>Functions:</strong></p>
<table class="autosummary longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#tlviz.model_evaluation.core_consistency" title="tlviz.model_evaluation.core_consistency"><code class="xref py py-obj docutils literal notranslate"><span class="pre">core_consistency</span></code></a>(cp_tensor, dataset[, ...])</p></td>
<td><p>Computes the core consistency <span id="id1">[<a class="reference internal" href="../references.html#id2" title="Rasmus Bro and Henk AL Kiers. A new efficient method for determining the number of components in parafac models. Journal of Chemometrics: A Journal of the Chemometrics Society, 17(5):274–286, 2003.">BK03</a>]</span></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tlviz.model_evaluation.estimate_core_tensor" title="tlviz.model_evaluation.estimate_core_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_core_tensor</span></code></a>(factors, dataset)</p></td>
<td><p>Efficient estimation of the Tucker core from a factor matrices and a data tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tlviz.model_evaluation.fit" title="tlviz.model_evaluation.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(cp_tensor, dataset[, sum_squared_dataset])</p></td>
<td><p>Compute the fit (1-relative sum squared error) for a given cp_tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tlviz.model_evaluation.predictive_power" title="tlviz.model_evaluation.predictive_power"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predictive_power</span></code></a>(cp_tensor, y, sklearn_estimator)</p></td>
<td><p>Use scikit-learn estimator to evaluate the predictive power of a factor matrix.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tlviz.model_evaluation.relative_sse" title="tlviz.model_evaluation.relative_sse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">relative_sse</span></code></a>(cp_tensor, dataset[, ...])</p></td>
<td><p>Compute the relative sum of squared error for a given cp_tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tlviz.model_evaluation.sse" title="tlviz.model_evaluation.sse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sse</span></code></a>(cp_tensor, dataset)</p></td>
<td><p>Compute the sum of squared error for a given cp_tensor.</p></td>
</tr>
</tbody>
</table>
<dl class="py function">
<dt class="sig sig-object py" id="tlviz.model_evaluation.core_consistency">
<span class="sig-prename descclassname"><span class="pre">tlviz.model_evaluation.</span></span><span class="sig-name descname"><span class="pre">core_consistency</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cp_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalised</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tlviz/model_evaluation.html#core_consistency"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tlviz.model_evaluation.core_consistency" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the core consistency <span id="id2">[<a class="reference internal" href="../references.html#id2" title="Rasmus Bro and Henk AL Kiers. A new efficient method for determining the number of components in parafac models. Journal of Chemometrics: A Journal of the Chemometrics Society, 17(5):274–286, 2003.">BK03</a>]</span></p>
<p>A CP model can be interpreted as a restricted Tucker model, where the
core tensor is constrained to be superdiagonal. For a third order tensor,
this means that the core tensor, <span class="math notranslate nohighlight">\(\mathcal{G}\)</span>, satisfy <span class="math notranslate nohighlight">\(g_{ijk}\neq0\)</span>
only if <span class="math notranslate nohighlight">\(i = j = k\)</span>. To compute the core consistency of a CP decomposition,
we use this property, and calculate the optimal Tucker core tensor given
the factor matrices of the CP model.</p>
<p>The key observation is that if the data tensor follows the assumptions
of the CP model, then the optimal core tensor should be similar to that
of the CP model, i. e. superdiagonal. However, if the data can be better
described by allowing for interactions between the components across modes,
then the core tensor will have non-zero off-diagonal. The core consistency
quantifies this measure and is defined as:</p>
<div class="math notranslate nohighlight">
\[\text{CC} = 100 - 100 \frac{\| \mathcal{G} - \mathcal{I} \|_F^2}{N}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> is the estimated core tensor, <span class="math notranslate nohighlight">\(\mathcal{I}\)</span>
is a superdiagonal tensor only ones on the superdiagonal and <span class="math notranslate nohighlight">\(N\)</span>
is a normalising factor, either equal to the number of components or the
squared frobenius norm of the estimated core tensor. A core consistency
score close to 100 indicates that the CP model is likely valid. If the
core consistency is low, however, then the model either has components
that describe noise or the data does not follow the model’s assumptions.
So the core consistency can help determine if the chosen number of
components is suitable.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>cp_tensor</strong><span class="classifier">CPTensor or tuple</span></dt><dd><p>TensorLy-style CPTensor object or tuple with weights as first
argument and a tuple of components as second argument</p>
</dd>
<dt><strong>dataset</strong><span class="classifier">np.ndarray</span></dt><dd><p>Data tensor that the cp_tensor is fitted against</p>
</dd>
<dt><strong>normalised</strong><span class="classifier">Bool (default=False)</span></dt><dd><p>If True, then the squared frobenius norm of the estimated core tensor
is used to normalise the core consistency. Otherwise, the number of
components is used.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">normalised=False</span></code>, then the core consistency formula coincides
with <span id="id3">[<a class="reference internal" href="../references.html#id2" title="Rasmus Bro and Henk AL Kiers. A new efficient method for determining the number of components in parafac models. Journal of Chemometrics: A Journal of the Chemometrics Society, 17(5):274–286, 2003.">BK03</a>]</span>, and if <code class="docutils literal notranslate"><span class="pre">normalised=True</span></code>, the core consistency
formula coincides with that used in the <a class="reference external" href="http://models.life.ku.dk/nwaytoolbox">N-Way toolbox</a>,
and is unlikely to be less than 0. For core consistencies close to
100, the formulas approximately coincide.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>The core consistency</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>We can use the core consistency diagonstic to determine the correct number of components
for a CP model. Here, we only fit one model, but in practice, you should fit multiple models
and select the one with the lowest SSE (to account for local minima) before computing the
core consistency.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tlviz.data</span> <span class="kn">import</span> <span class="n">simulated_random_cp_tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorly.decomposition</span> <span class="kn">import</span> <span class="n">parafac</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cp_tensor</span><span class="p">,</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">simulated_random_cp_tensor</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">),</span> <span class="mi">3</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Fit many CP models with different number of components</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">decomposition</span> <span class="o">=</span> <span class="n">parafac</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">cc</span> <span class="o">=</span> <span class="n">core_consistency</span><span class="p">(</span><span class="n">decomposition</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">normalised</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No. components: </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> - core consistency: </span><span class="si">{</span><span class="n">cc</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">No. components: 1 - core consistency: 100</span>
<span class="go">No. components: 2 - core consistency: 100</span>
<span class="go">No. components: 3 - core consistency: 81</span>
<span class="go">No. components: 4 - core consistency: 0</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This implementation uses the fast method of estimating the core tensor
<span id="id4">[<a class="reference internal" href="../references.html#id4" title="Paul E Buis and Wayne R Dyksen. Efficient vector and parallel manipulation of tensor products. ACM Transactions on Mathematical Software (TOMS), 22(1):18–23, 1996.">BD96</a>, <a class="reference internal" href="../references.html#id3" title="Evangelos E Papalexakis and Christos Faloutsos. Fast efficient and scalable core consistency diagnostic for the parafac decomposition for big sparse tensors. In 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 5441–5445. IEEE, 2015.">PF15</a>]</span></p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tlviz.model_evaluation.estimate_core_tensor">
<span class="sig-prename descclassname"><span class="pre">tlviz.model_evaluation.</span></span><span class="sig-name descname"><span class="pre">estimate_core_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">factors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tlviz/model_evaluation.html#estimate_core_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tlviz.model_evaluation.estimate_core_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Efficient estimation of the Tucker core from a factor matrices and a data tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>factors</strong><span class="classifier">tuple</span></dt><dd><p>Tuple of factor matrices used to estimate the core tensor from</p>
</dd>
<dt><strong>dataset</strong><span class="classifier">np.ndarray</span></dt><dd><p>The data tensor that the core tensor is estimated from</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>In the original paper, <span id="id5">Papalexakis and Faloutsos [<a class="reference internal" href="../references.html#id3" title="Evangelos E Papalexakis and Christos Faloutsos. Fast efficient and scalable core consistency diagnostic for the parafac decomposition for big sparse tensors. In 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 5441–5445. IEEE, 2015.">PF15</a>]</span> present an algorithm
for 3-way tensors. However, it is straightforward to generalise it to N-way tensors
by using the inverse tensor product formula in <span id="id6">[<a class="reference internal" href="../references.html#id4" title="Paul E Buis and Wayne R Dyksen. Efficient vector and parallel manipulation of tensor products. ACM Transactions on Mathematical Software (TOMS), 22(1):18–23, 1996.">BD96</a>]</span>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tlviz.model_evaluation.fit">
<span class="sig-prename descclassname"><span class="pre">tlviz.model_evaluation.</span></span><span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cp_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sum_squared_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tlviz/model_evaluation.html#fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tlviz.model_evaluation.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the fit (1-relative sum squared error) for a given cp_tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>cp_tensor</strong><span class="classifier">CPTensor or tuple</span></dt><dd><p>TensorLy-style CPTensor object or tuple with weights as first
argument and a tuple of components as second argument</p>
</dd>
<dt><strong>dataset</strong><span class="classifier">ndarray</span></dt><dd><p>Tensor approximated by <code class="docutils literal notranslate"><span class="pre">cp_tensor</span></code></p>
</dd>
<dt><strong>sum_squared_dataset: float (optional)</strong></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">sum(dataset**2)</span></code> is already computed, you can optionally provide it
using this argument to avoid unnecessary recalculation.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>The relative sum of squared error, <code class="docutils literal notranslate"><span class="pre">sum((X_hat</span> <span class="pre">-</span> <span class="pre">dataset)**2)/sum(dataset**2)</span></code>,
where <code class="docutils literal notranslate"><span class="pre">X_hat</span></code> is the dense tensor represented by <code class="docutils literal notranslate"><span class="pre">cp_tensor</span></code></p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Below, we create a random CP tensor and a random tensor and compute
the sum of squared error for these two tensors.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">tensorly</span> <span class="k">as</span> <span class="nn">tl</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorly.random</span> <span class="kn">import</span> <span class="n">random_cp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tlviz.model_evaluation</span> <span class="kn">import</span> <span class="n">fit</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">check_random_state</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cp</span> <span class="o">=</span> <span class="n">random_cp</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fit</span><span class="p">(</span><span class="n">cp</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="go">0.5182592745038558</span>
</pre></div>
</div>
<p>We can see that it is equal to 1 - relative SSE</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tlviz.model_evaluation</span> <span class="kn">import</span> <span class="n">relative_sse</span>
<span class="gp">&gt;&gt;&gt; </span><span class="mi">1</span> <span class="o">-</span> <span class="n">relative_sse</span><span class="p">(</span><span class="n">cp</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="go">0.5182592745038558</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tlviz.model_evaluation.predictive_power">
<span class="sig-prename descclassname"><span class="pre">tlviz.model_evaluation.</span></span><span class="sig-name descname"><span class="pre">predictive_power</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cp_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sklearn_estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tlviz/model_evaluation.html#predictive_power"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tlviz.model_evaluation.predictive_power" title="Permalink to this definition">¶</a></dt>
<dd><p>Use scikit-learn estimator to evaluate the predictive power of a factor matrix.</p>
<p>This is useful if you evaluate the components based on their predictive
power with respect to some task.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>factor_matrix</strong><span class="classifier">ndarray(ndim=2)</span></dt><dd><p>Factor matrix from a tensor decomposition model</p>
</dd>
<dt><strong>y</strong><span class="classifier">ndarray(ndim=1)</span></dt><dd><p>Prediction target for each row of the factor matrix in the given mode.
<code class="docutils literal notranslate"><span class="pre">y</span></code> should have same length as the first dimension of this factor
matrix (i.e. the length of the tensor along the given mode).</p>
</dd>
<dt><strong>sklearn_estimator</strong><span class="classifier">scikit learn estimator</span></dt><dd><p>Scikit learn estimator. Must have the <code class="docutils literal notranslate"><span class="pre">fit</span></code> and <code class="docutils literal notranslate"><span class="pre">predict</span></code> methods,
and if <code class="docutils literal notranslate"><span class="pre">metric</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>, then it should also have the <code class="docutils literal notranslate"><span class="pre">score</span></code>
method. See <a class="reference external" href="https://scikit-learn.org/stable/developers/develop.html">https://scikit-learn.org/stable/developers/develop.html</a>.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">int</span></dt><dd><p>Which mode to perform the scoring along</p>
</dd>
<dt><strong>metric</strong><span class="classifier">Callable</span></dt><dd><p>Callable (typically function) with the signature <code class="docutils literal notranslate"><span class="pre">metric(y_true,</span> <span class="pre">y_pred)</span></code>,
where <code class="docutils literal notranslate"><span class="pre">y_true=labels</span></code> and <code class="docutils literal notranslate"><span class="pre">y_pred</span></code> is the predicted values
obtained from <code class="docutils literal notranslate"><span class="pre">sklearn_estimator</span></code>. See
<a class="reference external" href="https://scikit-learn.org/stable/developers/develop.html#specific-models">https://scikit-learn.org/stable/developers/develop.html#specific-models</a>.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int (optional)</span></dt><dd><p>Alias for mode, if set, then mode cannot be set.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>Score based on the estimator’s performance.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<p><code class="docutils literal notranslate"><span class="pre">predictive_power</span></code> can be useful to evaluate the predictive power of a CP decomposition.
To illustrate this, we start by creating a simulated CP tensor and a variable we want to
predict that is linearly related to one of the factor matrices.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tlviz.data</span> <span class="kn">import</span> <span class="n">simulated_random_cp_tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cp_tensor</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">simulated_random_cp_tensor</span><span class="p">((</span><span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="mi">5</span><span class="p">,</span> <span class="n">noise_level</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">weights</span><span class="p">,</span> <span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span> <span class="o">=</span> <span class="n">cp_tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regression_coefficients</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span> <span class="o">=</span> <span class="n">A</span> <span class="o">@</span> <span class="n">regression_coefficients</span>
</pre></div>
</div>
<p>Next, we fit a PARAFAC model to this data</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorly.decomposition</span> <span class="kn">import</span> <span class="n">parafac</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est_cp_tensor</span> <span class="o">=</span> <span class="n">parafac</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<p>Finally, we see how well the estimated decomposition can describe our target variable, <code class="docutils literal notranslate"><span class="pre">Y</span></code>.
This will use the <span class="math notranslate nohighlight">\(R^2\)</span>-coefficient for scoring, as that is the default scoring method
for linear models.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tlviz.model_evaluation</span> <span class="kn">import</span> <span class="n">predictive_power</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear_regression</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r_squared</span> <span class="o">=</span> <span class="n">predictive_power</span><span class="p">(</span><span class="n">cp_tensor</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">linear_regression</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The R^2 coefficient is </span><span class="si">{</span><span class="n">r_squared</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">The R^2 coefficient is 1.00</span>
</pre></div>
</div>
<p>We can also specify our own scoring function</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">max_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">highest_error</span> <span class="o">=</span> <span class="n">predictive_power</span><span class="p">(</span><span class="n">cp_tensor</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">linear_regression</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">max_error</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The maximum error is </span><span class="si">{</span><span class="n">highest_error</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">The maximum error is 0.00</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tlviz.model_evaluation.relative_sse">
<span class="sig-prename descclassname"><span class="pre">tlviz.model_evaluation.</span></span><span class="sig-name descname"><span class="pre">relative_sse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cp_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sum_squared_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tlviz/model_evaluation.html#relative_sse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tlviz.model_evaluation.relative_sse" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the relative sum of squared error for a given cp_tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>cp_tensor</strong><span class="classifier">CPTensor or tuple</span></dt><dd><p>TensorLy-style CPTensor object or tuple with weights as first
argument and a tuple of components as second argument</p>
</dd>
<dt><strong>dataset</strong><span class="classifier">ndarray</span></dt><dd><p>Tensor approximated by <code class="docutils literal notranslate"><span class="pre">cp_tensor</span></code></p>
</dd>
<dt><strong>sum_squared_dataset: float (optional)</strong></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">sum(dataset**2)</span></code> is already computed, you can optionally provide it
using this argument to avoid unnecessary recalculation.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>The relative sum of squared error, <code class="docutils literal notranslate"><span class="pre">sum((X_hat</span> <span class="pre">-</span> <span class="pre">dataset)**2)/sum(dataset**2)</span></code>,
where <code class="docutils literal notranslate"><span class="pre">X_hat</span></code> is the dense tensor represented by <code class="docutils literal notranslate"><span class="pre">cp_tensor</span></code></p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Below, we create a random CP tensor and a random tensor and compute
the sum of squared error for these two tensors.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">tensorly</span> <span class="k">as</span> <span class="nn">tl</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorly.random</span> <span class="kn">import</span> <span class="n">random_cp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tlviz.model_evaluation</span> <span class="kn">import</span> <span class="n">relative_sse</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">check_random_state</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cp</span> <span class="o">=</span> <span class="n">random_cp</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">relative_sse</span><span class="p">(</span><span class="n">cp</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="go">0.4817407254961442</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="tlviz.model_evaluation.sse">
<span class="sig-prename descclassname"><span class="pre">tlviz.model_evaluation.</span></span><span class="sig-name descname"><span class="pre">sse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cp_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tlviz/model_evaluation.html#sse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tlviz.model_evaluation.sse" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the sum of squared error for a given cp_tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>cp_tensor</strong><span class="classifier">CPTensor or tuple</span></dt><dd><p>TensorLy-style CPTensor object or tuple with weights as first
argument and a tuple of components as second argument</p>
</dd>
<dt><strong>dataset</strong><span class="classifier">ndarray</span></dt><dd><p>Tensor approximated by <code class="docutils literal notranslate"><span class="pre">cp_tensor</span></code></p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>The sum of squared error, <code class="docutils literal notranslate"><span class="pre">sum((X_hat</span> <span class="pre">-</span> <span class="pre">dataset)**2)</span></code>, where <code class="docutils literal notranslate"><span class="pre">X_hat</span></code>
is the dense tensor represented by <code class="docutils literal notranslate"><span class="pre">cp_tensor</span></code></p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Below, we create a random CP tensor and a random tensor and compute
the sum of squared error for these two tensors.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">tensorly</span> <span class="k">as</span> <span class="nn">tl</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorly.random</span> <span class="kn">import</span> <span class="n">random_cp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tlviz.model_evaluation</span> <span class="kn">import</span> <span class="n">sse</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">check_random_state</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cp</span> <span class="o">=</span> <span class="n">random_cp</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sse</span><span class="p">(</span><span class="n">cp</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="go">18.948918157419186</span>
</pre></div>
</div>
</dd></dl>

</section>


        </div>

		
        <nav class="pagination" role="navigation" aria-label="pagination">
    
    <a class="button is-medium pagination-previous" href="factor_tools.html" title="previous page" accesskey="p">
        <span class="icon">
            <i class="fa fa-arrow-circle-left"></i>
        </span>
        <span>Factor tools</span>
    </a>
    
    
    <a class="button is-medium pagination-next" href="multimodel_evaluation.html" title="next page" accesskey="n">
        <span>Multi-model evaluation </span>
        <span class="icon">
            <i class="fa fa-arrow-circle-right"></i>
        </span>
    </a>
    
</nav>

        

      </section>

        <footer class="footer">
    <div class="content has-text-centered">
        <div class="block">
          &copy; Copyright 2021, Marie Roald &amp; Yngve Mardal Moe.<br/>
        </div>
      <div class="block">
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> and the <a href="tensorly.org"><strong>TensorLy</strong></a> theme by <a href="jeankossaifi.com">Jean Kossaifi</a>.
      </div>
    </div>
  </footer>

    </div>

	
    

    

  </div>
  </div>

  <!-- Include here scripts that need to be added after the page is loaded -->
  <script>
    function toggle_sidebar() {
        var element = document.getElementById("sidebar");
        var container = document.getElementById("column-container");
        var localtoccolumn = document.getElementById("localtoc-column");
        element.classList.toggle("hide-tablet");
        element.classList.toggle("is-hidden-mobile");
        container.classList.toggle("sidemenu-hidden");
        localtoccolumn.classList.toggle("is-one-fifth-widescreen");
        localtoccolumn.classList.toggle("is-2-desktop");
        localtoccolumn.classList.toggle("is-3-desktop");
    }
  </script> 



  </body>
</html>