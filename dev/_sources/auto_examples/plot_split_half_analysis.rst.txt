
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_split_half_analysis.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_split_half_analysis.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_split_half_analysis.py:


.. _split-half:

Split-half analysis for selecting the number of components
----------------------------------------------------------

In this example, we will look at how we can use split-half analysis to select the number of PARAFAC components.

The idea of split-half analysis is that we want to find the same underlying patterns if we look at different representative subsets of the same data.
To accomplish this, we split the dataset in two equally sized non-overlapping pieces along one mode and fit a PARAFAC model to both pieces.
Then, we compare the similarity of the factors in the other, non-split modes.

Generally, we would split the sample mode, but sometimes, it may also make sense to split other modes. For example,
if we have a time series and expect the same patterns to be present in two subsequent periods, then we may split
the data along the temporal mode instead.

.. GENERATED FROM PYTHON SOURCE LINES 19-21

Imports and utilities
^^^^^^^^^^^^^^^^^^^^^

.. GENERATED FROM PYTHON SOURCE LINES 21-31

.. code-block:: default


    import matplotlib.pyplot as plt
    import numpy as np
    import pandas as pd
    from tensorly.decomposition import parafac

    import tlviz

    rng = np.random.default_rng(0)








.. GENERATED FROM PYTHON SOURCE LINES 32-35

To fit PARAFAC models, we need to solve a non-convex optimization problem, possibly with local minima. It is
therefore useful to fit several models with the same number of components using many different random
initialisations.

.. GENERATED FROM PYTHON SOURCE LINES 35-53

.. code-block:: default



    def fit_many_parafac(X, num_components, num_inits=5):
        return [
            parafac(
                X,
                num_components,
                n_iter_max=1000,
                tol=1e-8,
                init="random",
                orthogonalise=True,
                linesearch=True,
                random_state=i,
            )
            for i in range(num_inits)
        ]









.. GENERATED FROM PYTHON SOURCE LINES 54-58

Creating simulated data
^^^^^^^^^^^^^^^^^^^^^^^

We start with some simulated data, since then, we know exactly how many components there are in the data.

.. GENERATED FROM PYTHON SOURCE LINES 58-62

.. code-block:: default


    cp_tensor, dataset = tlviz.data.simulated_random_cp_tensor((30, 40, 50), 4, noise_level=0.2, labelled=True)









.. GENERATED FROM PYTHON SOURCE LINES 63-67

Splitting the data
^^^^^^^^^^^^^^^^^^

We split the data randomly along the second mode

.. GENERATED FROM PYTHON SOURCE LINES 67-76

.. code-block:: default


    I, J, K = dataset.shape

    permutation = rng.permutation(J)
    splits = [
        dataset.loc[{"Mode 1": permutation[: J // 2]}],
        dataset.loc[{"Mode 1": permutation[J // 2 :]}],
    ]








.. GENERATED FROM PYTHON SOURCE LINES 77-81

Fitting models to the split data
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

We split the data randomly along the second mode

.. GENERATED FROM PYTHON SOURCE LINES 81-91

.. code-block:: default


    models = {}
    for rank in [1, 2, 3, 4, 5]:
        print(f"{rank} components")
        models[rank] = []
        for split in splits:
            current_models = fit_many_parafac(split.data, rank)
            current_model = tlviz.multimodel_evaluation.get_model_with_lowest_error(current_models, split)
            models[rank].append(current_model)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    1 components
    2 components
    3 components
    4 components
    5 components




.. GENERATED FROM PYTHON SOURCE LINES 92-99

Computing factor similarity
^^^^^^^^^^^^^^^^^^^^^^^^^^^

Now, we compute the similarity between the two splits for the different numbers of components.
However, we cannot compare the second mode (``mode=1``), since that was the mode we sampled randomly
in. Also, we cannot consider the weights in the factor match score since the weight will also be
affected by the sampling.

.. GENERATED FROM PYTHON SOURCE LINES 99-106

.. code-block:: default


    split_half_stability = {}
    for rank, (cp_1, cp_2) in models.items():
        fms = tlviz.factor_tools.factor_match_score(cp_1, cp_2, consider_weights=False, skip_mode=1)
        split_half_stability[rank] = fms









.. GENERATED FROM PYTHON SOURCE LINES 107-109

Plotting the  factor similarity
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. GENERATED FROM PYTHON SOURCE LINES 109-113

.. code-block:: default


    plt.plot(split_half_stability.keys(), split_half_stability.values(), "-o")
    plt.show()




.. image-sg:: /auto_examples/images/sphx_glr_plot_split_half_analysis_001.png
   :alt: plot split half analysis
   :srcset: /auto_examples/images/sphx_glr_plot_split_half_analysis_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 114-124

As we can see, there is a sharp drop in stability when increasing from four to five components.
This drop indicates that the patterns we find with a five-component model are not robust to small changes in the data.
In this case, this result is expected because we simulated the data and know that it contains only four components.
So to fit a five-component model to this four-component data, the model might split the information in one of the
"true" components into two or more model components and possibly mix some of the components.
Since this splitting and mixing can be done in many ways, we no longer have a stable decomposition, causing the
sharp drop we see in the plot.

So we see that visualising the split-half stability can be a helpful way to evaluate how many components you should
use to model your data.

.. GENERATED FROM PYTHON SOURCE LINES 126-140

Split-half analysis for the bike sharing data
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Here, we try split-half analysis on bike sharing data from Oslo. This dataset has five modes:

  * End station
  * Year
  * Month
  * Day of week
  * Hour of day

The dataset covers all bike trips during 2020 and 2021, and we would expect to find appoximately
the same patterns for the two years. We can therefore form two new tensors, one for 2020 and one
for 2021, fit PARAFAC models for these two datasets and compare the similarity of the components.

.. GENERATED FROM PYTHON SOURCE LINES 140-167

.. code-block:: default


    bike_data = tlviz.data.load_oslo_city_bike()

    splits = [
        bike_data.loc[{"Year": 2020}],
        bike_data.loc[{"Year": 2021}],
    ]

    bike_models = {}
    for rank in [1, 2, 3, 4, 5]:
        print(f"{rank} components")
        bike_models[rank] = []
        for split in splits:
            current_models = fit_many_parafac(split.data, rank)
            current_model = tlviz.multimodel_evaluation.get_model_with_lowest_error(current_models, split)
            bike_models[rank].append(current_model)

    bike_stability = {}
    for rank, (cp_1, cp_2) in bike_models.items():
        fms = tlviz.factor_tools.factor_match_score(cp_1, cp_2, consider_weights=False, skip_mode=1)
        bike_stability[rank] = fms


    plt.plot(bike_stability.keys(), bike_stability.values(), "-o")
    plt.show()





.. image-sg:: /auto_examples/images/sphx_glr_plot_split_half_analysis_002.png
   :alt: plot split half analysis
   :srcset: /auto_examples/images/sphx_glr_plot_split_half_analysis_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    1 components
    2 components
    3 components
    4 components
    5 components




.. GENERATED FROM PYTHON SOURCE LINES 168-171

Based on this split-half analysis, we see that we find three components that are present in both
years. The moment we go up to four components, the stability drastically falls, and it falls even
further with five components. This indicates that three components is a good choice for the model.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  9.925 seconds)


.. _sphx_glr_download_auto_examples_plot_split_half_analysis.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_split_half_analysis.py <plot_split_half_analysis.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_split_half_analysis.ipynb <plot_split_half_analysis.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
